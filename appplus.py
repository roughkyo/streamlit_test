import streamlit as st
import os
import google.generativeai as genai
from youtube_transcript_api import YouTubeTranscriptApi

# 1) API í‚¤ ì„¤ì • ë° ì´ˆê¸°í™”
gemini_api_key = st.sidebar.text_input(
    'ğŸ”‘ Gemini API í‚¤ ì…ë ¥', 
    value='AIzaSyDOTESWEgBjfYpkNsEeRQjSKgaVF_Y5D4Y', 
    type='password'  # â—â—â—ë¡œ ë§ˆìŠ¤í‚¹í•¨
)
if not gemini_api_key:
    gemini_api_key = os.getenv('GEMINI_API_KEY', '')
if not gemini_api_key:
    st.sidebar.error('API í‚¤ê°€ í•„ìš”í•¨. ì…ë ¥í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•˜ì„¸ìš”.')
    st.stop()

genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel('gemini-2.0-flash')

# 2) ì‚¬ì´ë“œë°”: URL ì…ë ¥ + ìŠ¬ë¼ì´ë” ì„¤ì •
st.sidebar.header('ì„¤ì •')
yt_url = st.sidebar.text_input(
    'â–¶ï¸ YouTube URL ë¶™ì—¬ë„£ê¸°', 
    'https://www.youtube.com/watch?v=kTFWhKrjMRs'
)
n_sentences = st.sidebar.slider(
    'ğŸ”– ìš”ì•½ ë¬¸ì¥ ìˆ˜ ì„ íƒ', 
    min_value=1, 
    max_value=10, 
    value=3
)

# 3) ìœ í‹¸ í•¨ìˆ˜ ì •ì˜
def get_ytid(url: str) -> str:
    """YouTube URLì—ì„œ ì˜ìƒ ID ì¶”ì¶œí•¨"""
    return url.split('/')[-1] if 'youtu.be' in url else url.split('=')[-1]

def fetch_transcript(ytid: str) -> str:
    """ìë§‰ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì³ ë°˜í™˜í•¨"""
    try:
        lst = YouTubeTranscriptApi.get_transcript(ytid, languages=['ko','en'])
        return " ".join([entry['text'] for entry in lst])
    except Exception as e:
        st.error(f'ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}')
        return ""

def chunk_text(text: str, max_chars: int = 3000) -> list[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ max_chars ë‹¨ìœ„ë¡œ ë¶„í• í•¨"""
    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]

# 4) ìš”ì•½ í•¨ìˆ˜ (ìŠ¬ë¼ì´ë” ê°’ ë°˜ì˜)
def summarize_chunks(chunks: list[str], n_sent: int) -> list[str]:
    """
    ê° ì²­í¬ë¥¼ ìµœëŒ€ n_sent ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•¨  
    - ë¶€ê°€ ì„¤ëª… ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜í•˜ë„ë¡ ì§€ì‹œí•¨
    """
    summaries = []
    for idx, chunk in enumerate(chunks, start=1):
        st.write(f'â³ ì²­í¬ {idx}/{len(chunks)} ìš”ì•½ ì¤‘â€¦')
        prompt = (
            f"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ë˜, **ìµœëŒ€ {n_sent}ë¬¸ì¥ ì´ë‚´**ë¡œ ìš”ì•½ ê²°ê³¼ë§Œ ë°˜í™˜í•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”:\n\n"
            + chunk
        )
        resp = model.generate_content(prompt)
        summaries.append(resp.text.strip())
    return summaries

def meta_summary(summaries: list[str], n_sent: int) -> str:
    """
    ì²­í¬ë³„ ìš”ì•½ì„ í•©ì³ ìµœì¢…ì ìœ¼ë¡œ ìµœëŒ€ n_sent ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•¨  
    - ìµœì¢… ê²°ê³¼ë§Œ ë°˜í™˜í•˜ë„ë¡ ì§€ì‹œí•¨
    """
    combined = "\n\n".join(summaries)
    prompt = (
        f"ì—¬ëŸ¬ ë¶€ë¶„ ìš”ì•½ì„ í•©ì³ **ìµœëŒ€ {n_sent}ë¬¸ì¥ ì´ë‚´**ë¡œ ìµœì¢… ìš”ì•½ ê²°ê³¼ë§Œ ë°˜í™˜í•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”:\n\n"
        + combined
    )
    resp = model.generate_content(prompt)
    return resp.text.strip()

# 5) â€˜ì˜ìƒ ìš”ì•½í•˜ê¸°â€™ ë²„íŠ¼ ì²˜ë¦¬
if st.sidebar.button('ì˜ìƒ ìš”ì•½í•˜ê¸°') and yt_url:
    ytid = get_ytid(yt_url)
    transcript = fetch_transcript(ytid)
    if not transcript:
        st.stop()

    # 5-1) ìë§‰ ë¶„í• 
    chunks = chunk_text(transcript)

    # 5-2) ì²­í¬ë³„ ìš”ì•½ (ìŠ¬ë¼ì´ë” ë°˜ì˜)
    part_summaries = summarize_chunks(chunks, n_sentences)

    # 5-3) ë©”íƒ€ ìš”ì•½ (ìŠ¬ë¼ì´ë” ë°˜ì˜)
    final_summary = meta_summary(part_summaries, n_sentences)

    # 5-4) ê²°ê³¼ í‘œì‹œ
    st.subheader('ğŸ“„ ìµœì¢… ì˜ìƒ ìš”ì•½ ê²°ê³¼')
    st.write(final_summary)

# 6) ì¸ë„¤ì¼ ì¶”ì¶œ ë° í‘œì‹œ
if yt_url:
    thumb_url = f'http://img.youtube.com/vi/{get_ytid(yt_url)}/hqdefault.jpg'
    st.image(thumb_url)
    st.write('ì¸ë„¤ì¼ URL:', thumb_url)
